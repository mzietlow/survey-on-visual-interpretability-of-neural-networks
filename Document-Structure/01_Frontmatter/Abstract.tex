\begin{abstract}
    In this paper we give a theoretical overview of methods for understanding non-linear predictors (primarily Neural Networks) visually. Our focus lies on heatmapping methods that try to assign to each input-variable the relevance of this variable towards the model-output. From our literature-review we derive a taxonomy of gradient\= and perturbation-based approaches. We provide an overview of commonly used metrics for evaluating the efficiency of such heatmapping-methods. Further, we describe a set of sanity-checks for assessing the reliability for a given metric.
\end{abstract}