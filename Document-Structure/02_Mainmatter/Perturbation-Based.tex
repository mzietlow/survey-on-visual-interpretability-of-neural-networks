\section{Perturbation-Based Methods}
Perturbation based methods for Visualizing NNs are methods, which compute “the attribution of an input feature (or set of features) by removing, masking or altering them, and running a forward pass on the new input, measuring the difference with the original output.” \fcite{Acona.2018} (Acona et al., p.2).
These methods “allow a direct estimation of the marginal effect of a feature” (\fcite{Acona.2018}, p.2)., but do not achieve the needed performance when it comes to a higher number of features.
Because of this, there are many new approaches in this field.
Various methods are based on perturbation of input data. In this meta study the focus will be on Prediction Difference Analysis, but multiple other methods will be mentioned and and the current state of research will be explained.

\subsection{Contrastive Explanations Method CEM (with Monotonic Attribute Functions)}
The Contrastive Explanations Method was first published by \fcite{Dhurandhar.2018} in 2018 in their paper "Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives".
The CEM approach aims to identify the minimal amount of pixels to justify a classification, called \glspl{pp} pertinent positives (PPs)\todo{fix}. On the other hand side it identifies the pixels as well, that need to be “turned off” in order to change the classification of the image. These pixels are called pertinent negatives (PNs). Like this, the most important pixels can be found \fcite{Luss.}.(Luss 2019). To make it easier to understand Luss et al. give an understandable example: “For example, when justifying the classification of a handwritten image of a 3, the method will identify a subset of non-zero or on-pixels within the 3 which by themselves are sufficient for the image to be predicted as a 3 even if all other pixels are turned off (that is, made zero to match background). Moreover, it will identify a minimal set of off-pixels which if turned on (viz. a horizontal line of pixels at the right top making the 3 look like a 5) will alter the classification.” (Luss p.2)
This example is visualized above (Dhurandhar et al.).
For the algorithm Dhurandhar et al. found formulas to calculate such PPs and PNs
They applied this method to a dataset of handwritten numbers, like seen in the example\todo{picture}. They trained a CNN, which finally reached an accuracy of 99.4\% and then used CEM to visualize these decisions. In addition they used a a convolutional autoencoder (CAE) for some results, which improves this method even further. In figure n the output of CEM is visualized. To be able to better see the improvements made by this method, LIME and LRP were applied to the same dataset. It can clearly be seen, that CEM´s results are better understandable for humans.

Luss et al. improved this method and made it applicable to RGB images.
They found, that “For colored images, PPs offer better direction as to what is important for the classification versus too much direction by LIME (shows too many features) or too little direction by Grad-CAM (only focuses on smiles), while for gray-scale images, neither PPs, LIME, or Grad-CAM are particularly informative versus PNs. “ (p.7)
