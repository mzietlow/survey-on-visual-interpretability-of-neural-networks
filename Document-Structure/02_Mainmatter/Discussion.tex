\section{Conclusion}
Concluding this literature-review on visual-interpretability of non-linear predictors (with significant focus on \glspl{nn}), this area of research feels more like a minefield, where every few months new work is published that either outperforms previous methods or renders them flat wrong~\cite{Kindermans.2019,Dombrowski.2019}. However, we find metrics to compare such methods to be either computationally expansive or unreliable (\cref{metrics:sanity-checks}). With interpretability as a requirement for certain application domains (especially in the european union), cooling is improbable.
\par
This paper summarized multiple methods, that aim to visualize these explanations. Since first methods were introduced in~\cite{RobnikSikonja.2008} many new approaches have evolved. Some of the most promising methods like \gls{cem} or PatternNet and PatternAttribution (\cref{subsect:patternnet-attribution}) have found new, but much more interpretable ways of explaining by standing upon the shoulders of previous research. Almost the complete corpus used for this survey is publicly available.
\par
And even though, there is no favorable method at this time and for most approaches much more research is necessary, there are more ways than ever to visualize \glspl{nn} in an understandable way.
\section{Future Research}
There have been many new approaches towards Perturbation-Based Methods in the last years. Methods like anchors or \gls{cem} are promising, but need more research in order to refine them and make them applicable to various types of data. 
\par
Besides, we find that new, reliable and less computational expensive metrics must be a priority for future research. This is a highly non-trivial task, because ground-truth is unavailable. As a first step we suggest that \gls{roar} (\cref{metrics:roar}) as the most promising metric should be evaluated under the sanity-check-framework for metrics (\cref{metrics:sanity-checks}).